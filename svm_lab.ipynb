{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18b0c44-2a75-45b9-91a9-0c60a802f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "class Args:\n",
    "    dir_model = 'model_svr'\n",
    "    lang = 'en'\n",
    "    label_type1 = 'pron'\n",
    "    label_type2 = 'prosody'\n",
    "    dir_list = ''\n",
    "    dir_list='/mnt/f/fluent/AI_exp_repo/datasets_list'\n",
    "    base_dim = 1024\n",
    "    output_dim = 1\n",
    "    audio_len_max = 200000\n",
    "    device ='cuda'\n",
    "args = Args()\n",
    "\n",
    "# Load the saved model and scaler\n",
    "model = joblib.load(os.path.join(args.dir_model, 'svr_model.joblib'))\n",
    "scaler = joblib.load(os.path.join(args.dir_model, 'scaler.joblib'))\n",
    "\n",
    "def load_or_extract_features(args, data_type):\n",
    "    \"\"\"Load features from file if they exist, otherwise extract them and save to file.\"\"\"\n",
    "    feature_dir = os.path.join(\"datasets_full_list_feature_extracted\", f\"lang_{args.lang}\")\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    feature_file = os.path.join(feature_dir, f\"{args.label_type1}_{data_type}.npz\")\n",
    "    print(f\"feature_file : {feature_file}\")\n",
    "    \n",
    "    if os.path.exists(feature_file):\n",
    "        print(f\"Loading features from {feature_file}\")\n",
    "        data = np.load(feature_file)\n",
    "        feat_X, feat_Y = data[\"X\"], data[\"Y\"]\n",
    "    else:\n",
    "        print(f\"Extracting features and saving to {feature_file}\")\n",
    "        feat_X, feat_Y = feat_extraction(args, data_type)\n",
    "        np.savez(feature_file, X=feat_X, Y=feat_Y)\n",
    "\n",
    "    print(f\"wav2vec2 feature {data_type}, {feat_X.shape}, {feat_Y.shape}\")\n",
    "    return feat_X, feat_Y\n",
    "    \n",
    "def open_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7234da-130c-4a65-8adb-c20b1d17ed85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def feat_extraction(args, data_type):\n",
    "    ''' wav2vec2 feature extraction part '''\n",
    "\n",
    "    fname_list = os.path.join(args.dir_list, f'lang_{args.lang}', f'{args.label_type1}_{data_type}.list')\n",
    "    filelist = open_file(fname_list)\n",
    "    data_len = len(filelist)\n",
    "\n",
    "    feat_X = np.zeros((data_len, args.base_dim), dtype=np.float32)  # features\n",
    "    feat_Y = np.zeros((data_len, 1), dtype=np.float32)  # labels\n",
    "\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(args.base_model).to(args.device)  # load wav2vec2 model\n",
    "\n",
    "    for idx, line in enumerate(filelist):\n",
    "\n",
    "        try:\n",
    "            fname, score1, score2, text = line.split('\\t')  # wavfile path, articulation score, prosody score, script\n",
    "        except:\n",
    "            data_len -= 1  # if list file format is wrong, we exclude it\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x, sr = audiofile.read(fname)\n",
    "        except:\n",
    "            data_len -= 1\n",
    "            continue\n",
    "\n",
    "        if args.label_type2 == 'articulation':\n",
    "            score = score1\n",
    "        else:\n",
    "            score = score2\n",
    "\n",
    "        if x.shape[-1] > args.audio_len_max:\n",
    "            x = x[:args.audio_len_max]  # if audio file is long, cut it to audio_len_max\n",
    "\n",
    "        x = torch.tensor(x, device=args.device).reshape(1, -1)\n",
    "        output = model(x, output_attentions=True, output_hidden_states=True, return_dict=True)  # wav2vec2 model output\n",
    "\n",
    "        feat_x = output.hidden_states[-1]  # last hidden state of wav2vec2, (1, frame, 1024)\n",
    "        feat_x = torch.mean(feat_x, axis=1).cpu().detach().numpy()  # pooled output along time axis, (1, 1024)\n",
    "\n",
    "        feat_X[idx, :] = feat_x\n",
    "        feat_Y[idx, 0] = float(score)\n",
    "\n",
    "    print(f\"wav2vec2 feature extraction {data_type}, {feat_X[:data_len, :].shape}, {feat_Y[:data_len, :].shape}\")\n",
    "\n",
    "    return feat_X[:data_len, :], feat_Y[:data_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e985ef-e35a-49b0-bf49-ef969f409530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_file : datasets_full_list_feature_extracted/lang_en/pron_test.npz\n",
      "Loading features from datasets_full_list_feature_extracted/lang_en/pron_test.npz\n",
      "wav2vec2 feature test, (8813, 1024), (8813, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (8813,1) and (8813,) not aligned: 1 (dim 1) != 8813 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23952/2250115251.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions using the loaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate the Pearson correlation coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpearson_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pearson Correlation Coefficient: {pearson_corr}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4804\u001b[0m         msg = (\"An input array is nearly constant; the computed \"\n\u001b[1;32m   4805\u001b[0m                \"correlation coefficient may be inaccurate.\")\n\u001b[1;32m   4806\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNearConstantInputWarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4808\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnormxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnormym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m     \u001b[0;31m# Presumably, if abs(r) > 1, then it is only some small artifact of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4811\u001b[0m     \u001b[0;31m# floating point arithmetic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (8813,1) and (8813,) not aligned: 1 (dim 1) != 8813 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Load or extract features for the dataset (e.g., 'test')\n",
    "test_feat_x, test_feat_y = load_or_extract_features(args, 'test')\n",
    "\n",
    "# Scale the features using the loaded scaler\n",
    "test_feat_x = scaler.transform(test_feat_x)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "test_preds = model.predict(test_feat_x)\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(test_feat_y, test_preds)\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c107850d-c6fe-4f31-aef4-7e9f53da66cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8813,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(test_feat_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42f6799-45a1-451a-ae52-7e5582c0c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: 0.7469743287759553\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Pearson correlation coefficient\n",
    "pearson_corr, _ = pearsonr(np.squeeze(test_feat_y), test_preds)\n",
    "\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9dacb67-fd13-4a08-bee7-a76424db7607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06ab79f4-5c15-46f7-bb49-a2e480254d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_file : datasets_full_list_feature_extracted/lang_en/pron_test.npz\n",
      "Loading features from datasets_full_list_feature_extracted/lang_en/pron_test.npz\n",
      "wav2vec2 feature test, (8813, 1024), (8813, 1)\n",
      "(8813, 1024)\n",
      "(8813, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 8813]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m first_sample_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(first_sample_x)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate the Mean Squared Error (MSE)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m mse_value \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfirst_sample_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_sample_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 8813]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load or extract features for the dataset (e.g., 'test')\n",
    "test_feat_x, test_feat_y = load_or_extract_features(args, 'test')\n",
    "\n",
    "# Scale the features using the loaded scaler\n",
    "test_feat_x = scaler.transform(test_feat_x)\n",
    "\n",
    "# Use only the first sample\n",
    "first_sample_x = test_feat_x  # Reshape to 2D array\n",
    "first_sample_y = test_feat_y\n",
    "print(first_sample_x.shape)\n",
    "print(first_sample_y.shape)\n",
    "\n",
    "# Make prediction using the loaded model\n",
    "first_sample_pred = model.predict(first_sample_x)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse_value = mean_squared_error([first_sample_y], first_sample_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_value}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken for the process: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e45a4-3bd9-4d1d-80f6-9b580a048bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoring",
   "language": "python",
   "name": "scoring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
